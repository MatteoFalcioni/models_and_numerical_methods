{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MatteoFalcioni/models_and_numerical_methods/blob/main/MakeMore_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VrCwY9Oi9l1X"
      },
      "outputs": [],
      "source": [
        "# Few Links to discuss in class....\n",
        "\n",
        "# https://www.python.org/\n",
        "\n",
        "# https://pytorch.org/\n",
        "\n",
        "# https://en.wikipedia.org/wiki/Andrej_Karpathy\n",
        "\n",
        "\n",
        "# https://youtu.be/PaCmpygFfXo\n",
        "# https://github.com/karpathy/makemore\n",
        "\n",
        "\n"
      ],
      "id": "VrCwY9Oi9l1X"
    },
    {
      "cell_type": "code",
      "source": [
        "3+2"
      ],
      "metadata": {
        "id": "3PNC2lgX-OdM"
      },
      "id": "3PNC2lgX-OdM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LRBmQxsv9l1Y"
      },
      "outputs": [],
      "source": [
        "#...Aim: construct a language model, character based, able to 'learn' how to 'reproduce' P(x_n |x_1,...,x_{n-1})\n",
        "# we start by counting...."
      ],
      "id": "LRBmQxsv9l1Y"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0o8BkJ7m9l1Z"
      },
      "outputs": [],
      "source": [
        "#adapt the code to your data....\n",
        "\n",
        "words=open('Data/nomi_italiani.txt','r').read().splitlines()"
      ],
      "id": "0o8BkJ7m9l1Z"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FHSkHkQi9l1Z"
      },
      "outputs": [],
      "source": [
        "words[:10]"
      ],
      "id": "FHSkHkQi9l1Z"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IMJjtggV9l1Z"
      },
      "outputs": [],
      "source": [
        "len(words)"
      ],
      "id": "IMJjtggV9l1Z"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ul6EBk1k9l1a"
      },
      "outputs": [],
      "source": [
        "min(len(w) for w in words)"
      ],
      "id": "ul6EBk1k9l1a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lhXz7NRc9l1a"
      },
      "outputs": [],
      "source": [
        "max(len(w) for w in words)"
      ],
      "id": "lhXz7NRc9l1a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "00ZSnnZ59l1a"
      },
      "outputs": [],
      "source": [
        "L=[len(w) for w in words]\n",
        "\n",
        "words[L.index(max(L))]"
      ],
      "id": "00ZSnnZ59l1a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-4h3P0Qr9l1a"
      },
      "outputs": [],
      "source": [
        "L"
      ],
      "id": "-4h3P0Qr9l1a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "enrca7TP9l1a"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "random.seed(158) # for reproducibility....often used !!\n",
        "random.shuffle(words)\n",
        "words[:10]"
      ],
      "id": "enrca7TP9l1a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PlsA4Tvf9l1b"
      },
      "outputs": [],
      "source": [
        "words[:10]"
      ],
      "id": "PlsA4Tvf9l1b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A9xMAmu_9l1b"
      },
      "outputs": [],
      "source": [
        "# discuss zip.... https://docs.python.org/3/library/functions.html#zip\n",
        "\n",
        "for w in words[:1]:\n",
        "    for ch1, ch2 in zip(w,w[1:]):\n",
        "        print(ch1,ch2)"
      ],
      "id": "A9xMAmu_9l1b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FMyjXsiV9l1b"
      },
      "outputs": [],
      "source": [
        "w"
      ],
      "id": "FMyjXsiV9l1b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xnOf6nW49l1b"
      },
      "outputs": [],
      "source": [
        "list(w)"
      ],
      "id": "xnOf6nW49l1b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H6Ai2g9o9l1c"
      },
      "outputs": [],
      "source": [
        "w[1:]"
      ],
      "id": "H6Ai2g9o9l1c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N1uKYRKx9l1c"
      },
      "outputs": [],
      "source": [
        "? zip"
      ],
      "id": "N1uKYRKx9l1c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jGyQlGZ39l1c"
      },
      "outputs": [],
      "source": [
        "list(w)"
      ],
      "id": "jGyQlGZ39l1c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MYWNykfj9l1c"
      },
      "outputs": [],
      "source": [
        "for w in words[:3]:\n",
        "    chs=['<S>']+list(w)+['<S>']\n",
        "    for ch1, ch2 in zip(chs,chs[1:]):\n",
        "        \n",
        "        print(ch1,ch2)"
      ],
      "id": "MYWNykfj9l1c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OM6oYzlC9l1c"
      },
      "outputs": [],
      "source": [
        "b={}\n",
        "for w in words[:3]:\n",
        "    chs=['<S>']+list(w)+['<S>']\n",
        "    for ch1, ch2 in zip(chs,chs[1:]):\n",
        "        bigram=(ch1,ch2)\n",
        "        b[bigram]=b.get(bigram,0)+1\n",
        "        print(ch1,ch2)"
      ],
      "id": "OM6oYzlC9l1c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BYGVDlVV9l1c"
      },
      "outputs": [],
      "source": [
        "b"
      ],
      "id": "BYGVDlVV9l1c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O4_ZMr269l1d"
      },
      "outputs": [],
      "source": [],
      "id": "O4_ZMr269l1d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q8U1An-c9l1d"
      },
      "outputs": [],
      "source": [
        "b={}\n",
        "for w in words:\n",
        "    chs=['<S>']+list(w)+['<E>']\n",
        "    for ch1, ch2 in zip(chs,chs[1:]):\n",
        "        bigram=(ch1,ch2)\n",
        "        b[bigram]=b.get(bigram,0)+1\n",
        "        "
      ],
      "id": "Q8U1An-c9l1d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-9tHqQyt9l1d"
      },
      "outputs": [],
      "source": [
        "b"
      ],
      "id": "-9tHqQyt9l1d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HpAp4m3S9l1d"
      },
      "outputs": [],
      "source": [
        "b.items()"
      ],
      "id": "HpAp4m3S9l1d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N5OXqu_59l1d"
      },
      "outputs": [],
      "source": [
        "sorted(b.items(), key = lambda z: -z[1])"
      ],
      "id": "N5OXqu_59l1d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HgZYmTY29l1d"
      },
      "outputs": [],
      "source": [
        "# now we code information in a 2 dim array: row ch1 culumn ch2, ... value: how often ch2 follow ch1...pytorch.org"
      ],
      "id": "HgZYmTY29l1d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VtdtYohD9l1d"
      },
      "outputs": [],
      "source": [
        "import torch"
      ],
      "id": "VtdtYohD9l1d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "99Eyp7iQ9l1e"
      },
      "outputs": [],
      "source": [
        "a=torch.zeros((3,5))\n",
        "a"
      ],
      "id": "99Eyp7iQ9l1e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KgseHkXx9l1e"
      },
      "outputs": [],
      "source": [
        "a.dtype"
      ],
      "id": "KgseHkXx9l1e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bkvMYBF99l1e"
      },
      "outputs": [],
      "source": [
        "a=torch.zeros((3,5), dtype=torch.int32)\n",
        "a"
      ],
      "id": "bkvMYBF99l1e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "33q66qGh9l1e"
      },
      "outputs": [],
      "source": [
        "a[1,3]=11\n",
        "a"
      ],
      "id": "33q66qGh9l1e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zt7w5IY39l1e"
      },
      "outputs": [],
      "source": [
        "w=set(list(words[10]))\n",
        "w"
      ],
      "id": "Zt7w5IY39l1e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-y5r9cOZ9l1e"
      },
      "outputs": [],
      "source": [
        "chars=sorted(list(set(''.join(words))))\n",
        "print(len(chars))\n",
        "chars"
      ],
      "id": "-y5r9cOZ9l1e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xWkbtUNv9l1e"
      },
      "outputs": [],
      "source": [
        "set([0,0,1,2,2,3,3,3])"
      ],
      "id": "xWkbtUNv9l1e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1AYyss229l1e"
      },
      "outputs": [],
      "source": [
        "len(chars)"
      ],
      "id": "1AYyss229l1e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Jv7L5Af9l1f"
      },
      "outputs": [],
      "source": [
        "N=torch.zeros((29,29),dtype=torch.int32)"
      ],
      "id": "-Jv7L5Af9l1f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pPA1TyZz9l1f"
      },
      "outputs": [],
      "source": [
        "chars=sorted(list(set(''.join(words))))\n",
        "stoi={s:i for i,s in enumerate(chars)}\n",
        "stoi"
      ],
      "id": "pPA1TyZz9l1f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5lDUVq8f9l1f"
      },
      "outputs": [],
      "source": [
        "stoi['<S>']=27\n",
        "stoi['<E>']=28\n",
        "stoi"
      ],
      "id": "5lDUVq8f9l1f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cEP5S7Or9l1f"
      },
      "outputs": [],
      "source": [
        "\n",
        "for w in words:\n",
        "    chs=['<S>']+list(w)+['<S>']\n",
        "    for ch1, ch2 in zip(chs,chs[1:]):\n",
        "        ix1=stoi[ch1]\n",
        "        ix2=stoi[ch2]\n",
        "        N[ix1,ix2] +=1"
      ],
      "id": "cEP5S7Or9l1f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XYRwjWa59l1f"
      },
      "outputs": [],
      "source": [
        "N"
      ],
      "id": "XYRwjWa59l1f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5SBHPubl9l1f"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(N)"
      ],
      "id": "5SBHPubl9l1f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "liFrZXOs9l1f"
      },
      "outputs": [],
      "source": [
        "# stoi={s:i for i,s in enumerate(chars)}\n",
        "\n",
        "itos={i:s for s,i in stoi.items()}\n",
        "itos"
      ],
      "id": "liFrZXOs9l1f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nrLgexAM9l1g"
      },
      "outputs": [],
      "source": [
        "N[3,3]"
      ],
      "id": "nrLgexAM9l1g"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GYJu3u_b9l1g"
      },
      "outputs": [],
      "source": [
        "N[3,3].item()"
      ],
      "id": "GYJu3u_b9l1g"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pb0y9BB59l1g"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.figure(figsize=(16,16))\n",
        "plt.imshow(N,cmap='Blues')\n",
        "for i in range(29):\n",
        "    for j in range(29):\n",
        "        chstr=itos[i]+itos[j]\n",
        "        plt.text(j,i,chstr,ha='center', va='bottom', color='gray')\n",
        "        plt.text(j,i,N[i,j].item(),ha='center', va='top', color='gray')\n",
        "plt.axis('off')"
      ],
      "id": "Pb0y9BB59l1g"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FfjK9avR9l1g"
      },
      "outputs": [],
      "source": [
        "chars=sorted(list(set(''.join(words))))\n",
        "stoi={s:i+1 for i,s in enumerate(chars)}\n",
        "stoi['.']=0\n",
        "itos={i:s for s,i in stoi.items()}"
      ],
      "id": "FfjK9avR9l1g"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b-NUALQY9l1g"
      },
      "outputs": [],
      "source": [
        "stoi"
      ],
      "id": "b-NUALQY9l1g"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tcoO-OU49l1g"
      },
      "outputs": [],
      "source": [
        "itos"
      ],
      "id": "tcoO-OU49l1g"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ng4OSp5T9l1h"
      },
      "outputs": [],
      "source": [
        "N=torch.zeros((28,28),dtype=torch.int32)"
      ],
      "id": "Ng4OSp5T9l1h"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9xPpNwqs9l1h"
      },
      "outputs": [],
      "source": [
        "for w in words:\n",
        "    chs=['.']+list(w)+['.']\n",
        "    for ch1, ch2 in zip(chs,chs[1:]):\n",
        "        ix1=stoi[ch1]\n",
        "        ix2=stoi[ch2]\n",
        "        N[ix1,ix2] +=1"
      ],
      "id": "9xPpNwqs9l1h"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ydTunP2n9l1h"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.figure(figsize=(16,16))\n",
        "plt.imshow(N,cmap='Blues')\n",
        "for i in range(28):\n",
        "    for j in range(28):\n",
        "        chstr=itos[i]+itos[j]\n",
        "        plt.text(j,i,chstr,ha='center', va='bottom', color='gray')\n",
        "        plt.text(j,i,N[i,j].item(),ha='center', va='top', color='gray')\n",
        "plt.axis('off')"
      ],
      "id": "ydTunP2n9l1h"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cwZl0L5Q9l1h"
      },
      "outputs": [],
      "source": [
        "N[0]\n"
      ],
      "id": "cwZl0L5Q9l1h"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JcWa4AqH9l1h"
      },
      "outputs": [],
      "source": [
        "# probability vector\n",
        "\n",
        "p=N[0].float()\n",
        "p=p/p.sum()\n",
        "p"
      ],
      "id": "JcWa4AqH9l1h"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pIJGzWyj9l1h"
      },
      "outputs": [],
      "source": [
        "p.sum()"
      ],
      "id": "pIJGzWyj9l1h"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aMeQmyBI9l1h"
      },
      "outputs": [],
      "source": [
        "#g=torch.Generator().manual_seed(123450)\n",
        "p=torch.rand(15)\n",
        "print(p)\n",
        "p=p/p.sum()\n",
        "p"
      ],
      "id": "aMeQmyBI9l1h"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bro3sFtT9l1i"
      },
      "outputs": [],
      "source": [
        "# sample from this distribution....using torch multinomial distribution\n",
        "\n",
        "g=torch.Generator().manual_seed(12342502)\n",
        "p=torch.rand(3,generator=g)\n",
        "p=p/p.sum()\n",
        "p"
      ],
      "id": "bro3sFtT9l1i"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-cR737YC9l1i"
      },
      "outputs": [],
      "source": [
        "torch.multinomial(p,num_samples=200,replacement=True,generator=g)"
      ],
      "id": "-cR737YC9l1i"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dtiyP1MJ9l1i"
      },
      "outputs": [],
      "source": [
        "# back to p....\n",
        "\n",
        "p=N[0].float()\n",
        "print(p)\n",
        "p=p/p.sum()\n",
        "p"
      ],
      "id": "dtiyP1MJ9l1i"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sB-iXmV_9l1i"
      },
      "outputs": [],
      "source": [
        "g=torch.Generator().manual_seed(123450)\n",
        "torch.multinomial(p,num_samples=10,replacement=True,generator=g)"
      ],
      "id": "sB-iXmV_9l1i"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XAKMh3YO9l1i"
      },
      "outputs": [],
      "source": [
        "p.shape"
      ],
      "id": "XAKMh3YO9l1i"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BeR6tJLK9l1i"
      },
      "outputs": [],
      "source": [
        "g=torch.Generator().manual_seed(123450)\n",
        "ix=torch.multinomial(p,num_samples=1,replacement=True,generator=g).item()\n",
        "itos[ix]"
      ],
      "id": "BeR6tJLK9l1i"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "cPpxzbR09l1i"
      },
      "outputs": [],
      "source": [
        "g=torch.Generator().manual_seed(123450)\n",
        "\n",
        "for i in range(10):\n",
        "    out=[]\n",
        "    ix=0\n",
        "    while True:\n",
        "        p= N[ix].float()\n",
        "        p=p/p.sum()\n",
        "        # try to sample from uniform and compare\n",
        "        #p=torch.ones(28)/28.0\n",
        "        ix=torch.multinomial(p,num_samples=1,replacement=True,generator=g).item()\n",
        "        out.append(itos[ix])\n",
        "        if ix==0:\n",
        "            break\n",
        "    print(''.join(out))\n",
        "    "
      ],
      "id": "cPpxzbR09l1i"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8VIy5wSB9l1i"
      },
      "outputs": [],
      "source": [
        "# see 'broadcastable' in torch !!\n",
        "\n",
        "P=N.float()\n",
        "P=P/P.sum(1,keepdim=True)\n",
        "#P/P.sum()\n",
        "P"
      ],
      "id": "8VIy5wSB9l1i"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y6IKK59Q9l1j"
      },
      "outputs": [],
      "source": [
        "P[1].sum()"
      ],
      "id": "Y6IKK59Q9l1j"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EoW49DUA9l1j"
      },
      "outputs": [],
      "source": [
        "g=torch.Generator().manual_seed(12340)\n",
        "\n",
        "for i in range(10):\n",
        "    out=[]\n",
        "    ix=0\n",
        "    while True:\n",
        "        p=P[ix]\n",
        "        # to avoid the following twos over and over....\n",
        "        #p= N[ix].float()\n",
        "        #p=p/p.sum()\n",
        "        # try to sample from uniform and compare\n",
        "        # p=torch.ones(28)/28.0\n",
        "        ix=torch.multinomial(p,num_samples=1,replacement=True,generator=g).item()\n",
        "        out.append(itos[ix])\n",
        "        if ix==0:\n",
        "            break\n",
        "    print(''.join(out))\n",
        "    "
      ],
      "id": "EoW49DUA9l1j"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-6Z53DY9l1j"
      },
      "outputs": [],
      "source": [
        "# we 'trained' the model (P) on bigram and 'sample'......\n",
        "# NOW we want to EVALUATE the quality of the model into a SINGLE number\n",
        "\n",
        "for w in words[0:3]:\n",
        "    chs=['.']+list(w)+['.']\n",
        "    for ch1, ch2 in zip(chs,chs[1:]):\n",
        "        ix1=stoi[ch1]\n",
        "        ix2=stoi[ch2]\n",
        "        prob=P[ix1,ix2]\n",
        "        print(f'{ch1}{ch2}:{prob:.4f}')"
      ],
      "id": "z-6Z53DY9l1j"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bn3lxTyJ9l1j"
      },
      "outputs": [],
      "source": [
        "# Finished here on first MakeMore Lecture......12/04/2023....continuing on friday..."
      ],
      "id": "Bn3lxTyJ9l1j"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y7xdSMOn9l1j"
      },
      "outputs": [],
      "source": [
        "# Recap of lecture 12/04/2023 MakeMore part 1: putting togethere what we disucssed last time...\n",
        "\n",
        "# packages we need \n",
        "\n",
        "import random\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Read Data\n",
        "\n",
        "words=open('Data/nomi_italiani.txt','r').read().splitlines()\n",
        "\n",
        "\n",
        "random.seed(158) # for reproducibility....often used !!\n",
        "random.shuffle(words)\n",
        "\n",
        "# built vocabulary and simple encoder/decoder \n",
        "\n",
        "chars=sorted(list(set(''.join(words))))\n",
        "stoi={s:i+1 for i,s in enumerate(chars)}\n",
        "stoi['.']=0\n",
        "itos={i:s for s,i in stoi.items()}\n",
        "\n",
        "# Counting bigram\n",
        "\n",
        "\n",
        "N=torch.zeros((28,28),dtype=torch.int32)\n",
        "\n",
        "for w in words:\n",
        "    chs=['.']+list(w)+['.']\n",
        "    for ch1, ch2 in zip(chs,chs[1:]):\n",
        "        ix1=stoi[ch1]\n",
        "        ix2=stoi[ch2]\n",
        "        N[ix1,ix2] +=1\n",
        "        \n",
        "#Normalize Row to have Markovian Matrix P (each row is a prob. distribution)\n",
        "\n",
        "P=N.float()\n",
        "P=P/P.sum(1,keepdim=True) # broadcasting at work !!! ...more in class...\n",
        "#P=P/P.sum(1) # = P/P.sum(1,keepdim=False)"
      ],
      "id": "y7xdSMOn9l1j"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "crKg0ALaAzoO"
      },
      "id": "crKg0ALaAzoO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.figure(figsize=(16,16))\n",
        "plt.imshow(N,cmap='Blues')\n",
        "for i in range(28):\n",
        "    for j in range(28):\n",
        "        chstr=itos[i]+itos[j]\n",
        "        plt.text(j,i,chstr,ha='center', va='bottom', color='gray')\n",
        "        plt.text(j,i,N[i,j].item(),ha='center', va='top', color='gray')\n",
        "plt.axis('off')"
      ],
      "metadata": {
        "id": "6qWr7vib_-mA"
      },
      "id": "6qWr7vib_-mA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bradcasting Semantics: https://pytorch.org/docs/stable/notes/broadcasting.html\n",
        "# back to\n",
        "\n",
        "P=N.float()\n",
        "print(P.shape)\n",
        "P=P/P.sum(1,keepdim=True) # broadcasting at work !!! \n"
      ],
      "metadata": {
        "id": "TBXAS1UxD_Md"
      },
      "id": "TBXAS1UxD_Md",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aN0AS5bK9l1j"
      },
      "outputs": [],
      "source": [
        "P=N.float()\n",
        "X=P.sum(1,keepdim=True)\n",
        "Y=P.sum(1)\n",
        "print(P.shape,X.shape,Y.shape)\n",
        "print(X,Y)"
      ],
      "id": "aN0AS5bK9l1j"
    },
    {
      "cell_type": "code",
      "source": [
        "A=torch.tensor([0,1,2,3,4,5,6,7])\n",
        "A.view(8)\n"
      ],
      "metadata": {
        "id": "yiW-xC5JFXzq"
      },
      "id": "yiW-xC5JFXzq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RfSRqIqc9l1j"
      },
      "outputs": [],
      "source": [
        "\n",
        "X1=P/X\n",
        "Y1=P/Y\n",
        "print(X1.shape, Y1.shape)\n",
        "print(X1[3].sum(),Y1[3].sum())"
      ],
      "id": "RfSRqIqc9l1j"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "adJwBn5-9l1k"
      },
      "outputs": [],
      "source": [
        "# what is going on....\n",
        "X1[0]"
      ],
      "id": "adJwBn5-9l1k"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cwPlsTVW9l1k"
      },
      "outputs": [],
      "source": [
        "X1[0].sum()"
      ],
      "id": "cwPlsTVW9l1k"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qje8N8LT9l1k"
      },
      "outputs": [],
      "source": [
        "Y1[0].sum()"
      ],
      "id": "qje8N8LT9l1k"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JV5SEA7s9l1k"
      },
      "outputs": [],
      "source": [
        "Y1[:,10].sum()"
      ],
      "id": "JV5SEA7s9l1k"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1uok7pjF9l1k"
      },
      "outputs": [],
      "source": [
        "X[0]"
      ],
      "id": "1uok7pjF9l1k"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DnF_JUQ_9l1k"
      },
      "outputs": [],
      "source": [
        "#and as we expect....\n",
        "X1[0]*X[0]"
      ],
      "id": "DnF_JUQ_9l1k"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LepEkC6r9l1k"
      },
      "outputs": [],
      "source": [
        "P[0]"
      ],
      "id": "LepEkC6r9l1k"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eo5GRfbx9l1k"
      },
      "outputs": [],
      "source": [
        "#but.....\n",
        "Y1[0]*Y[0]"
      ],
      "id": "eo5GRfbx9l1k"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZOaB_w39l1l"
      },
      "outputs": [],
      "source": [
        "# even if...... got it ??\n",
        "Y1[0]*Y"
      ],
      "id": "VZOaB_w39l1l"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rF1iNLYj9l1l"
      },
      "outputs": [],
      "source": [],
      "id": "rF1iNLYj9l1l"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RZVCfU_E9l1l"
      },
      "outputs": [],
      "source": [
        "# now understand this........\n",
        "\n",
        "print(X1.shape, X1[0].shape,X.shape, (X1[0]*X).shape)"
      ],
      "id": "RZVCfU_E9l1l"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EmZLdY5N9l1l"
      },
      "outputs": [],
      "source": [
        "# We can now sample and generate....\n",
        "\n",
        "g=torch.Generator().manual_seed(12340)\n",
        "\n",
        "for i in range(10):\n",
        "    out=[]\n",
        "    ix=0\n",
        "    while True:\n",
        "        p=P[ix]\n",
        "        # to avoid the following twos over and over....\n",
        "        #p= N[ix].float()\n",
        "        #p=p/p.sum()\n",
        "        # try to sample from uniform and compare\n",
        "        # p=torch.ones(28)/28.0\n",
        "        ix=torch.multinomial(p,num_samples=1,replacement=True,generator=g).item()\n",
        "        out.append(itos[ix])\n",
        "        if ix==0:\n",
        "            break\n",
        "    print(''.join(out))\n",
        "    "
      ],
      "id": "EmZLdY5N9l1l"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ivxGvifK9l1l"
      },
      "outputs": [],
      "source": [],
      "id": "ivxGvifK9l1l"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S6jxLYRv9l1l"
      },
      "outputs": [],
      "source": [
        "# we 'trained' the model (P) on bigram and 'sample'......\n",
        "# NOW we want to EVALUATE the quality of the model into a SINGLE number\n",
        "\n",
        "# log-likelhood !!  log(a*b*c)=log a + log b + log c\n",
        "log_likelihood=0.0\n",
        "n=0\n",
        "for w in words[:3]:\n",
        "    chs=['.']+list(w)+['.']\n",
        "    for ch1, ch2 in zip(chs,chs[1:]):\n",
        "        ix1=stoi[ch1]\n",
        "        ix2=stoi[ch2]\n",
        "        prob=P[ix1,ix2]\n",
        "        logprob=torch.log(prob)\n",
        "        log_likelihood += logprob\n",
        "        n +=1\n",
        "        print(f'{ch1}{ch2}:{prob:.4f}:{logprob:.4f}')\n",
        "print(f'{log_likelihood=}')\n",
        "nll=-log_likelihood\n",
        "print(f'{nll=}')\n",
        "print(f'{nll/n}')"
      ],
      "id": "S6jxLYRv9l1l"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s-Zj3Qlr9l1m"
      },
      "outputs": [],
      "source": [],
      "id": "s-Zj3Qlr9l1m"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7p3kX3X99l1m"
      },
      "outputs": [],
      "source": [
        "# i.e.\n",
        "# GOAL: maximazie likelihood of the data w.r.t. model parameter (statistical modeling, i.e. elements of P by counting)\n",
        "# equivalent to maximize the log likelihood (because log is monotonic)\n",
        "# equivalent to minimize the negative log likelihood\n",
        "# equivalent to minimizing the average negative log likelihood "
      ],
      "id": "7p3kX3X99l1m"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "__5keR3K9l1m"
      },
      "outputs": [],
      "source": [
        "# we can compute log likelihood for any names, even with never seen transitions...infinite log like....\n",
        "\n",
        "log_likelihood=0.0\n",
        "n=0\n",
        "#for w in words[:3]:\n",
        "for w in ['mirko']:\n",
        "#for w in ['mirkoo']:\n",
        "    chs=['.']+list(w)+['.']\n",
        "    for ch1, ch2 in zip(chs,chs[1:]):\n",
        "        ix1=stoi[ch1]\n",
        "        ix2=stoi[ch2]\n",
        "        prob=P[ix1,ix2]\n",
        "        logprob=torch.log(prob)\n",
        "        log_likelihood += logprob\n",
        "        n +=1\n",
        "        print(f'{ch1}{ch2}:{prob:.4f}')\n",
        "print(f'{log_likelihood=}')\n",
        "nll=-log_likelihood\n",
        "print(f'{nll=}')\n",
        "print(f'{nll/n}')"
      ],
      "id": "__5keR3K9l1m"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tKB2p1UK9l1m"
      },
      "outputs": [],
      "source": [
        "# to prevent infinity we use SMOOTHING.....\n",
        "# instead of P=N.float()....K-> infty, we get uniform distribution !!\n",
        "K=1\n",
        "P=(N+K).float()\n",
        "P=P/P.sum(1,keepdim=True)"
      ],
      "id": "tKB2p1UK9l1m"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZItHmYP9l1m"
      },
      "outputs": [],
      "source": [
        "# P was computed (trained) by counting bigram...this approach is not scalable to n-gram...discuss in class...\n",
        "# We need to change prospective (neural network) ... but ending in the same spot as before!!\n",
        "# again,  given a caracter we are going to predict the (conditioned) proability distribution over all characters....\n",
        "# we just ask a neural network to do it efficiently....\n",
        "#...using the minimization of the negative averaged log likelhood (sort of conditional/relative entropy)to drive the learing process \n",
        "\n"
      ],
      "id": "wZItHmYP9l1m"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PeTWaZVR9l1m"
      },
      "outputs": [],
      "source": [
        "# we will be using 'gradient' optimization and we need to define the training set...one character and the next one we read in the data..\n",
        "# create the training set of bigrams (x,y)\n",
        "xs,ys =[],[]\n",
        "\n",
        "for w in words[:1]:\n",
        "    chs=['.']+list(w)+['.']\n",
        "    for ch1, ch2 in zip(chs,chs[1:]):\n",
        "        ix1=stoi[ch1]\n",
        "        ix2=stoi[ch2]\n",
        "        print(ch1,ch2)\n",
        "        xs.append(ix1)\n",
        "        ys.append(ix2)\n",
        "\n",
        "xs= torch.tensor(xs)\n",
        "ys=torch.tensor(ys)\n",
        "print(xs)\n",
        "print(ys)\n"
      ],
      "id": "PeTWaZVR9l1m"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dmk_oQQK9l1m"
      },
      "outputs": [],
      "source": [
        "# need to adapt to \"neural network\" architecture (show and discuss 1-layer  wj*x +bj)\n",
        "# .... one_hot encoding.....https://pytorch.org/docs/stable/generated/torch.nn.functional.one_hot.html\n",
        "# ... delta function....\n",
        "import torch.nn.functional as F\n",
        "xenc=F.one_hot(xs,num_classes=28).float()\n",
        "xenc\n"
      ],
      "id": "Dmk_oQQK9l1m"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TmmyOKNB9l1n"
      },
      "outputs": [],
      "source": [
        "xenc.shape"
      ],
      "id": "TmmyOKNB9l1n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GzmCEDMG9l1n"
      },
      "outputs": [],
      "source": [
        "xenc.dtype"
      ],
      "id": "GzmCEDMG9l1n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O8Pe-xzf9l1n"
      },
      "outputs": [],
      "source": [
        "plt.imshow(xenc)"
      ],
      "id": "O8Pe-xzf9l1n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ptbSaMto9l1n"
      },
      "outputs": [],
      "source": [
        "# we now ilmplement the first neuron.... W.x + b \n",
        "# torch.random and normal distribution\n",
        "# https://pytorch.org/docs/stable/generated/torch.rand.html\n",
        "\n",
        "W=torch.randn((28,1))\n",
        "\n",
        "xenc @ W"
      ],
      "id": "ptbSaMto9l1n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "94rA6JH39l1n"
      },
      "outputs": [],
      "source": [
        "#...we want 28 neuron in output\n",
        "\n",
        "W=torch.randn((28,28))\n",
        "\n",
        "xenc @ W"
      ],
      "id": "94rA6JH39l1n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YPFxQB0n9l1n"
      },
      "outputs": [],
      "source": [
        "(xenc @ W).shape"
      ],
      "id": "YPFxQB0n9l1n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oDTG3D1y9l1n"
      },
      "outputs": [],
      "source": [
        "# weights in the coloumn and pointwise multiplication........ pytorch take care of it...\n",
        "print((xenc @ W)[3,13])# 13th-neuron in 3 example....\n",
        "print((xenc[3]*W[:,13]).sum())"
      ],
      "id": "oDTG3D1y9l1n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1_qaDfj49l1o"
      },
      "outputs": [],
      "source": [
        "# how to interpret W ??? \n",
        "#look at the weigth, negative and positive.... - log(N) !! \n",
        "#  discussed in class........Softmax !!\n",
        "\n",
        "logits= xenc @ W # log-counts\n",
        "print(logits)\n",
        "counts= logits.exp() # equivalent N\n",
        "print(counts)\n",
        "probs=  counts/counts.sum(1,keepdims=True)\n",
        "probs"
      ],
      "id": "1_qaDfj49l1o"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HGJb_nKi9l1o"
      },
      "outputs": [],
      "source": [
        "probs.shape # one probability distribution for each example...."
      ],
      "id": "HGJb_nKi9l1o"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "an6bWuqS9l1o"
      },
      "outputs": [],
      "source": [
        "probs[1].sum()"
      ],
      "id": "an6bWuqS9l1o"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qaxB9VH59l1o"
      },
      "outputs": [],
      "source": [
        "# we can now interpret the outputs as probability.... the conditional distribution...\n",
        "# how likle the next characters will be.-.....can we otpimize ????\n",
        "probs[0]"
      ],
      "id": "qaxB9VH59l1o"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MsU6U-fw9l1o"
      },
      "outputs": [],
      "source": [
        "probs[1].shape"
      ],
      "id": "MsU6U-fw9l1o"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N-Q5qnx39l1o"
      },
      "outputs": [],
      "source": [
        "# SUMMARY ---------------------------------------------------------"
      ],
      "id": "N-Q5qnx39l1o"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yoScTc1J9l1o"
      },
      "outputs": [],
      "source": [
        "len(xs)"
      ],
      "id": "yoScTc1J9l1o"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2TEGHKus9l1o"
      },
      "outputs": [],
      "source": [
        "ys"
      ],
      "id": "2TEGHKus9l1o"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vXtmQamP9l1p"
      },
      "outputs": [],
      "source": [
        "# randomly initialize 28 neurons' weights, each neuron recevies 28 inputs\n",
        "g=torch.Generator().manual_seed(123450)\n",
        "W=torch.randn((28,28),generator=g)"
      ],
      "id": "vXtmQamP9l1p"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FClNGbds9l1p"
      },
      "outputs": [],
      "source": [
        "#... a sequence of 'differentiable' operations....ready fro back propagation...discuss in class\n",
        "\n",
        "\n",
        "xenc=F.one_hot(xs,num_classes=28).float() # input to network: one-hot encoding\n",
        "logits=xenc @ W # predict log-counts\n",
        "counts=logits.exp() # counts, equivalent to N !!\n",
        "probs=counts/counts.sum(1,keepdims=True)  # probabilites for next character\n",
        "#btw: the last two lines here are together called 'SoftMax'"
      ],
      "id": "FClNGbds9l1p"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Ha4t9oy9l1p"
      },
      "outputs": [],
      "source": [
        "probs.shape"
      ],
      "id": "4Ha4t9oy9l1p"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OM99NxCD9l1p"
      },
      "outputs": [],
      "source": [
        "1/28"
      ],
      "id": "OM99NxCD9l1p"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0hQHLp1X9l1p"
      },
      "outputs": [],
      "source": [
        "# just to break down the example....\n",
        "nlls=torch.zeros(6)\n",
        "for i in range(6):\n",
        "    #i-th bigram:\n",
        "    x=xs[i].item() # input character index\n",
        "    y=ys[i].item() # label character index\n",
        "    print('----------')\n",
        "    print(f'bigram example {i+1}: {itos[x]}{itos[y]} (indexes {x},{y})')\n",
        "    print('input to the neural net:',x)\n",
        "    print('output probabilites from the neural net:',probs[i])\n",
        "    print('label (actual next character):',y)\n",
        "    p=probs[i,y]\n",
        "    print('probability assigned by the net to the correct character:', p.item())\n",
        "    logp=torch.log(p)\n",
        "    print('log likelihood:',logp.item())\n",
        "    nll=-logp\n",
        "    print('negative log likelihood:',nll.item())\n",
        "    nlls[i]=nll\n",
        "    \n",
        "print('============')\n",
        "print('average negative log likelihood, i.e. loss =',nlls.mean().item())\n"
      ],
      "id": "0hQHLp1X9l1p"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3UcfpbWC9l1p"
      },
      "outputs": [],
      "source": [],
      "id": "3UcfpbWC9l1p"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ksLsn14H9l1p"
      },
      "outputs": [],
      "source": [
        "# chnge the seeds, re-sample W and try again.......\n"
      ],
      "id": "ksLsn14H9l1p"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xTIuLoQx9l1p"
      },
      "outputs": [],
      "source": [],
      "id": "xTIuLoQx9l1p"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RUnwgCsR9l1p"
      },
      "outputs": [],
      "source": [
        "## optimization: forward and backward....."
      ],
      "id": "RUnwgCsR9l1p"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iww1nHkF9l1p"
      },
      "outputs": [],
      "source": [
        "# nlls is made by differential functions and we try to optimize using gradient discendent..\n",
        "\n",
        "print(probs[torch.arange(6),ys])\n",
        "loss=-probs[torch.arange(6),ys].log().mean()\n",
        "print(loss)\n"
      ],
      "id": "iww1nHkF9l1p"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8IMmww5u9l1q"
      },
      "outputs": [],
      "source": [
        "# randomly initialize 28 neurons' weights, each neuron recevies 28 inputs\n",
        "g=torch.Generator().manual_seed(123450)\n",
        "W=torch.randn((28,28),generator=g, requires_grad=True) # comment on requires_grad"
      ],
      "id": "8IMmww5u9l1q"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k_9Sc7wq9l1q"
      },
      "outputs": [],
      "source": [
        "# forward pass\n",
        "xenc=F.one_hot(xs,num_classes=28).float() # input to network: one-hot encoding\n",
        "logits=xenc @ W # predict log-counts\n",
        "counts=logits.exp() # counts, equivalent to N !!\n",
        "probs=counts/counts.sum(1,keepdims=True) # probabilities of the next character\n",
        "loss=-probs[torch.arange(6),ys].log().mean()"
      ],
      "id": "k_9Sc7wq9l1q"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jfs672Ao9l1q"
      },
      "outputs": [],
      "source": [
        "probs.shape"
      ],
      "id": "Jfs672Ao9l1q"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fk3zxLJU9l1q"
      },
      "outputs": [],
      "source": [
        "torch.arange(8)"
      ],
      "id": "Fk3zxLJU9l1q"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wd2wpNhB9l1q"
      },
      "outputs": [],
      "source": [
        "ys"
      ],
      "id": "Wd2wpNhB9l1q"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_mEjo9gg9l1q"
      },
      "outputs": [],
      "source": [
        "W.grad= None "
      ],
      "id": "_mEjo9gg9l1q"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KV0xWAS19l1q"
      },
      "outputs": [],
      "source": [
        "print(W.grad)"
      ],
      "id": "KV0xWAS19l1q"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EwL8t10v9l1q"
      },
      "outputs": [],
      "source": [
        "# backward pass\n",
        "W.grad= None # comment in class ! set to zero the gradient !\n",
        "loss.backward() # lot of computations hidden here"
      ],
      "id": "EwL8t10v9l1q"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZZ0DeISo9l1q"
      },
      "outputs": [],
      "source": [
        "W.grad"
      ],
      "id": "ZZ0DeISo9l1q"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H4NI6Lzr9l1r"
      },
      "outputs": [],
      "source": [
        "W.shape"
      ],
      "id": "H4NI6Lzr9l1r"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NcIVGTav9l1r"
      },
      "outputs": [],
      "source": [
        "W.grad.shape"
      ],
      "id": "NcIVGTav9l1r"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "36mdFNty9l1r"
      },
      "outputs": [],
      "source": [
        "# update parameter\n",
        "W.data += -0.1 * W.grad"
      ],
      "id": "36mdFNty9l1r"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eLPu45HN9l1r"
      },
      "outputs": [],
      "source": [
        "# sample few times.....\n",
        "\n",
        "print(loss.item())"
      ],
      "id": "eLPu45HN9l1r"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NUiYNzWP9l1r"
      },
      "outputs": [],
      "source": [
        "# optimization...now for real...."
      ],
      "id": "NUiYNzWP9l1r"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yHW8wlVk9l1r"
      },
      "outputs": [],
      "source": [
        "# create the data set\n",
        "\n",
        "xs,ys =[],[]\n",
        "\n",
        "for w in words:\n",
        "    chs=['.']+list(w)+['.']\n",
        "    for ch1, ch2 in zip(chs,chs[1:]):\n",
        "        ix1=stoi[ch1]\n",
        "        ix2=stoi[ch2]\n",
        "        xs.append(ix1)\n",
        "        ys.append(ix2)\n",
        "\n",
        "xs= torch.tensor(xs)\n",
        "ys=torch.tensor(ys)\n",
        "num=xs.nelement() # add this...comment\n",
        "print('number of samples: ', num)\n",
        "\n",
        "# initialize the (one layer) 'network'\n",
        "g=torch.Generator().manual_seed(123450)\n",
        "W=torch.randn((28,28),generator=g, requires_grad=True)"
      ],
      "id": "yHW8wlVk9l1r"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ae5M0DxL9l1r"
      },
      "outputs": [],
      "source": [
        "# gradient descent\n",
        "\n",
        "for k in range(100):\n",
        "    # forward pass\n",
        "    xenc=F.one_hot(xs,num_classes=28).float() # input to network: one-hot encoding\n",
        "    logits=xenc @ W # predict log-counts\n",
        "    counts=logits.exp() # counts, equivalent to N !!\n",
        "    probs=counts/counts.sum(1,keepdims=True) # probabilities of the next character\n",
        "    loss=-probs[torch.arange(num),ys].log().mean()\n",
        "    print('loss', loss.item())\n",
        "    # backward pass\n",
        "    W.grad= None # comment in class ! set to zero the gradient !\n",
        "    loss.backward() # lot of computations hidden here\n",
        "    # update parameter\n",
        "    # try different 'learning rate': .1, ... 50\n",
        "    W.data += -10 * W.grad"
      ],
      "id": "ae5M0DxL9l1r"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dGcwkFSf9l1r"
      },
      "outputs": [],
      "source": [
        "# now we can 'generalize' changing the network structure (all the rest remain the same) and try to do better\n",
        "# this network approach is 'scalable', the 'direct' one by counting ngrams is NOT!!\n",
        "# comments in class..."
      ],
      "id": "dGcwkFSf9l1r"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7h0sLaX9l1r"
      },
      "outputs": [],
      "source": [
        "# finally, sample from the neural net model\n",
        "g=torch.Generator().manual_seed(123450)\n",
        "\n",
        "for i in range(15):\n",
        "    out=[]\n",
        "    ix=0\n",
        "    while True:\n",
        "        # before.....\n",
        "        p=P[ix]\n",
        "        # now...\n",
        "        xenc=F.one_hot(torch.tensor([ix]),num_classes=28).float() # input to network: one-hot encoding\n",
        "        logits=xenc @ W # predict log-counts\n",
        "        counts=logits.exp() # counts, equivalent to N !!\n",
        "        #p=counts/counts.sum(1,keepdims=True) # probabilities of the next character\n",
        "        \n",
        "        ix=torch.multinomial(p,num_samples=1,replacement=True,generator=g).item()\n",
        "        out.append(itos[ix])\n",
        "        if ix==0:\n",
        "            break\n",
        "    print(''.join(out))\n",
        "    "
      ],
      "id": "c7h0sLaX9l1r"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xS8J7fuy9l1s"
      },
      "outputs": [],
      "source": [],
      "id": "xS8J7fuy9l1s"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bCvCu5g09l1s"
      },
      "outputs": [],
      "source": [],
      "id": "bCvCu5g09l1s"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d1Hi3syV9l1s"
      },
      "outputs": [],
      "source": [],
      "id": "d1Hi3syV9l1s"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SxnGbTlJ9l1s"
      },
      "outputs": [],
      "source": [],
      "id": "SxnGbTlJ9l1s"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}